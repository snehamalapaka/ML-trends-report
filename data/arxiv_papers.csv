title,summary,authors,published,url
GoT-R1: Unleashing Reasoning Capability of MLLM for Visual Generation with Reinforcement Learning,"Visual generation models have made remarkable progress in creating realistic
images from text prompts, yet struggle with complex prompts that specify
multiple objects with precise spatial relationships and attributes. Effective
handling of such prompts requires explicit reasoning about the semantic content
and spatial layout. We present GoT-R1, a framework that applies reinforcement
learning to enhance semantic-spatial reasoning in visual generation. Building
upon the Generation Chain-of-Thought approach, GoT-R1 enables models to
autonomously discover effective reasoning strategies beyond predefined
templates through carefully designed reinforcement learning. To achieve this,
we propose a dual-stage multi-dimensional reward framework that leverages MLLMs
to evaluate both the reasoning process and final output, enabling effective
supervision across the entire generation pipeline. The reward system assesses
semantic alignment, spatial accuracy, and visual quality in a unified approach.
Experimental results demonstrate significant improvements on T2I-CompBench
benchmark, particularly in compositional tasks involving precise spatial
relationships and attribute binding. GoT-R1 advances the state-of-the-art in
image generation by successfully transferring sophisticated reasoning
capabilities to the visual generation domain. To facilitate future research, we
make our code and pretrained models publicly available at
https://github.com/gogoduan/GoT-R1.","['Chengqi Duan', 'Rongyao Fang', 'Yuqing Wang', 'Kun Wang', 'Linjiang Huang', 'Xingyu Zeng', 'Hongsheng Li', 'Xihui Liu']",2025-05-22,http://arxiv.org/abs/2505.17022v1
Let Androids Dream of Electric Sheep: A Human-like Image Implication Understanding and Reasoning Framework,"Metaphorical comprehension in images remains a critical challenge for AI
systems, as existing models struggle to grasp the nuanced cultural, emotional,
and contextual implications embedded in visual content. While multimodal large
language models (MLLMs) excel in basic Visual Question Answer (VQA) tasks, they
struggle with a fundamental limitation on image implication tasks: contextual
gaps that obscure the relationships between different visual elements and their
abstract meanings. Inspired by the human cognitive process, we propose Let
Androids Dream (LAD), a novel framework for image implication understanding and
reasoning. LAD addresses contextual missing through the three-stage framework:
(1) Perception: converting visual information into rich and multi-level textual
representations, (2) Search: iteratively searching and integrating cross-domain
knowledge to resolve ambiguity, and (3) Reasoning: generating context-alignment
image implication via explicit reasoning. Our framework with the lightweight
GPT-4o-mini model achieves SOTA performance compared to 15+ MLLMs on English
image implication benchmark and a huge improvement on Chinese benchmark,
performing comparable with the GPT-4o model on Multiple-Choice Question (MCQ)
and outperforms 36.7% on Open-Style Question (OSQ). Additionally, our work
provides new insights into how AI can more effectively interpret image
implications, advancing the field of vision-language reasoning and human-AI
interaction. Our project is publicly available at
https://github.com/MING-ZCH/Let-Androids-Dream-of-Electric-Sheep.","['Chenhao Zhang', 'Yazhe Niu']",2025-05-22,http://arxiv.org/abs/2505.17019v1
Delving into RL for Image Generation with CoT: A Study on DPO vs. GRPO,"Recent advancements underscore the significant role of Reinforcement Learning
(RL) in enhancing the Chain-of-Thought (CoT) reasoning capabilities of large
language models (LLMs). Two prominent RL algorithms, Direct Preference
Optimization (DPO) and Group Relative Policy Optimization (GRPO), are central
to these developments, showcasing different pros and cons. Autoregressive image
generation, also interpretable as a sequential CoT reasoning process, presents
unique challenges distinct from LLM-based CoT reasoning. These encompass
ensuring text-image consistency, improving image aesthetic quality, and
designing sophisticated reward models, rather than relying on simpler
rule-based rewards. While recent efforts have extended RL to this domain, these
explorations typically lack an in-depth analysis of the domain-specific
challenges and the characteristics of different RL strategies. To bridge this
gap, we provide the first comprehensive investigation of the GRPO and DPO
algorithms in autoregressive image generation, evaluating their in-domain
performance and out-of-domain generalization, while scrutinizing the impact of
different reward models on their respective capabilities. Our findings reveal
that GRPO and DPO exhibit distinct advantages, and crucially, that reward
models possessing stronger intrinsic generalization capabilities potentially
enhance the generalization potential of the applied RL algorithms. Furthermore,
we systematically explore three prevalent scaling strategies to enhance both
their in-domain and out-of-domain proficiency, deriving unique insights into
efficiently scaling performance for each paradigm. We hope our study paves a
new path for inspiring future work on developing more effective RL algorithms
to achieve robust CoT reasoning in the realm of autoregressive image
generation. Code is released at
https://github.com/ZiyuGuo99/Image-Generation-CoT","['Chengzhuo Tong', 'Ziyu Guo', 'Renrui Zhang', 'Wenyu Shan', 'Xinyu Wei', 'Zhenghao Xing', 'Hongsheng Li', 'Pheng-Ann Heng']",2025-05-22,http://arxiv.org/abs/2505.17017v1
Interactive Post-Training for Vision-Language-Action Models,"We introduce RIPT-VLA, a simple and scalable reinforcement-learning-based
interactive post-training paradigm that fine-tunes pretrained
Vision-Language-Action (VLA) models using only sparse binary success rewards.
Existing VLA training pipelines rely heavily on offline expert demonstration
data and supervised imitation, limiting their ability to adapt to new tasks and
environments under low-data regimes. RIPT-VLA addresses this by enabling
interactive post-training with a stable policy optimization algorithm based on
dynamic rollout sampling and leave-one-out advantage estimation.
  RIPT-VLA has the following characteristics. First, it applies to various VLA
models, resulting in an improvement on the lightweight QueST model by 21.2%,
and the 7B OpenVLA-OFT model to an unprecedented 97.5% success rate. Second, it
is computationally efficient and data-efficient: with only one demonstration,
RIPT-VLA enables an unworkable SFT model (4%) to succeed with a 97% success
rate within 15 iterations. Furthermore, we demonstrate that the policy learned
by RIPT-VLA generalizes across different tasks and scenarios and is robust to
the initial state context. These results highlight RIPT-VLA as a practical and
effective paradigm for post-training VLA models through minimal supervision.","['Shuhan Tan', 'Kairan Dou', 'Yue Zhao', 'Philipp Krähenbühl']",2025-05-22,http://arxiv.org/abs/2505.17016v1
When Are Concepts Erased From Diffusion Models?,"Concept erasure, the ability to selectively prevent a model from generating
specific concepts, has attracted growing interest, with various approaches
emerging to address the challenge. However, it remains unclear how thoroughly
these methods erase the target concept. We begin by proposing two conceptual
models for the erasure mechanism in diffusion models: (i) reducing the
likelihood of generating the target concept, and (ii) interfering with the
model's internal guidance mechanisms. To thoroughly assess whether a concept
has been truly erased from the model, we introduce a suite of independent
evaluations. Our evaluation framework includes adversarial attacks, novel
probing techniques, and analysis of the model's alternative generations in
place of the erased concept. Our results shed light on the tension between
minimizing side effects and maintaining robustness to adversarial prompts.
Broadly, our work underlines the importance of comprehensive evaluation for
erasure in diffusion models.","['Kevin Lu', 'Nicky Kriplani', 'Rohit Gandikota', 'Minh Pham', 'David Bau', 'Chinmay Hegde', 'Niv Cohen']",2025-05-22,http://arxiv.org/abs/2505.17013v1
SpatialScore: Towards Unified Evaluation for Multimodal Spatial Understanding,"Multimodal large language models (MLLMs) have achieved impressive success in
question-answering tasks, yet their capabilities for spatial understanding are
less explored. This work investigates a critical question: do existing MLLMs
possess 3D spatial perception and understanding abilities? Concretely, we make
the following contributions in this paper: (i) we introduce VGBench, a
benchmark specifically designed to assess MLLMs for visual geometry perception,
e.g., camera pose and motion estimation; (ii) we propose SpatialScore, the most
comprehensive and diverse multimodal spatial understanding benchmark to date,
integrating VGBench with relevant data from the other 11 existing datasets.
This benchmark comprises 28K samples across various spatial understanding
tasks, modalities, and QA formats, along with a carefully curated challenging
subset, SpatialScore-Hard; (iii) we develop SpatialAgent, a novel multi-agent
system incorporating 9 specialized tools for spatial understanding, supporting
both Plan-Execute and ReAct reasoning paradigms; (iv) we conduct extensive
evaluations to reveal persistent challenges in spatial reasoning while
demonstrating the effectiveness of SpatialAgent. We believe SpatialScore will
offer valuable insights and serve as a rigorous benchmark for the next
evolution of MLLMs.","['Haoning Wu', 'Xiao Huang', 'Yaohui Chen', 'Ya Zhang', 'Yanfeng Wang', 'Weidi Xie']",2025-05-22,http://arxiv.org/abs/2505.17012v1
Understanding Prompt Tuning and In-Context Learning via Meta-Learning,"Prompting is one of the main ways to adapt a pretrained model to target
tasks. Besides manually constructing prompts, many prompt optimization methods
have been proposed in the literature. Method development is mainly empirically
driven, with less emphasis on a conceptual understanding of prompting. In this
paper we discuss how optimal prompting can be understood through a Bayesian
view, which also implies some fundamental limitations of prompting that can
only be overcome by tuning weights. The paper explains in detail how
meta-trained neural networks behave as Bayesian predictors over the pretraining
distribution, whose hallmark feature is rapid in-context adaptation. Optimal
prompting can be studied formally as conditioning these Bayesian predictors,
yielding criteria for target tasks where optimal prompting is and is not
possible. We support the theory with educational experiments on LSTMs and
Transformers, where we compare different versions of prefix-tuning and
different weight-tuning methods. We also confirm that soft prefixes, which are
sequences of real-valued vectors outside the token alphabet, can lead to very
effective prompts for trained and even untrained networks by manipulating
activations in ways that are not achievable by hard tokens. This adds an
important mechanistic aspect beyond the conceptual Bayesian theory.","['Tim Genewein', 'Kevin Wenliang Li', 'Jordi Grau-Moya', 'Anian Ruoss', 'Laurent Orseau', 'Marcus Hutter']",2025-05-22,http://arxiv.org/abs/2505.17010v1
R1-Searcher++: Incentivizing the Dynamic Knowledge Acquisition of LLMs via Reinforcement Learning,"Large Language Models (LLMs) are powerful but prone to hallucinations due to
static knowledge. Retrieval-Augmented Generation (RAG) helps by injecting
external information, but current methods often are costly, generalize poorly,
or ignore the internal knowledge of the model. In this paper, we introduce
R1-Searcher++, a novel framework designed to train LLMs to adaptively leverage
both internal and external knowledge sources. R1-Searcher++ employs a two-stage
training strategy: an initial SFT Cold-start phase for preliminary format
learning, followed by RL for Dynamic Knowledge Acquisition. The RL stage uses
outcome-supervision to encourage exploration, incorporates a reward mechanism
for internal knowledge utilization, and integrates a memorization mechanism to
continuously assimilate retrieved information, thereby enriching the model's
internal knowledge. By leveraging internal knowledge and external search
engine, the model continuously improves its capabilities, enabling efficient
retrieval-augmented reasoning. Our experiments demonstrate that R1-Searcher++
outperforms previous RAG and reasoning methods and achieves efficient
retrieval. The code is available at
https://github.com/RUCAIBox/R1-Searcher-plus.","['Huatong Song', 'Jinhao Jiang', 'Wenqing Tian', 'Zhipeng Chen', 'Yuhuan Wu', 'Jiahao Zhao', 'Yingqian Min', 'Wayne Xin Zhao', 'Lei Fang', 'Ji-Rong Wen']",2025-05-22,http://arxiv.org/abs/2505.17005v1
Guided Diffusion Sampling on Function Spaces with Applications to PDEs,"We propose a general framework for conditional sampling in PDE-based inverse
problems, targeting the recovery of whole solutions from extremely sparse or
noisy measurements. This is accomplished by a function-space diffusion model
and plug-and-play guidance for conditioning. Our method first trains an
unconditional discretization-agnostic denoising model using neural operator
architectures. At inference, we refine the samples to satisfy sparse
observation data via a gradient-based guidance mechanism. Through rigorous
mathematical analysis, we extend Tweedie's formula to infinite-dimensional
Hilbert spaces, providing the theoretical foundation for our posterior sampling
approach. Our method (FunDPS) accurately captures posterior distributions in
function spaces under minimal supervision and severe data scarcity. Across five
PDE tasks with only 3% observation, our method achieves an average 32% accuracy
improvement over state-of-the-art fixed-resolution diffusion baselines while
reducing sampling steps by 4x. Furthermore, multi-resolution fine-tuning
ensures strong cross-resolution generalizability. To the best of our knowledge,
this is the first diffusion-based framework to operate independently of
discretization, offering a practical and flexible solution for forward and
inverse problems in the context of PDEs. Code is available at
https://github.com/neuraloperator/FunDPS","['Jiachen Yao', 'Abbas Mammadov', 'Julius Berner', 'Gavin Kerrigan', 'Jong Chul Ye', 'Kamyar Azizzadenesheli', 'Anima Anandkumar']",2025-05-22,http://arxiv.org/abs/2505.17004v1
Sufficient conditions for offline reactivation in recurrent neural networks,"During periods of quiescence, such as sleep, neural activity in many brain
circuits resembles that observed during periods of task engagement. However,
the precise conditions under which task-optimized networks can autonomously
reactivate the same network states responsible for online behavior is poorly
understood. In this study, we develop a mathematical framework that outlines
sufficient conditions for the emergence of neural reactivation in circuits that
encode features of smoothly varying stimuli. We demonstrate mathematically that
noisy recurrent networks optimized to track environmental state variables using
change-based sensory information naturally develop denoising dynamics, which,
in the absence of input, cause the network to revisit state configurations
observed during periods of online activity. We validate our findings using
numerical experiments on two canonical neuroscience tasks: spatial position
estimation based on self-motion cues, and head direction estimation based on
angular velocity cues. Overall, our work provides theoretical support for
modeling offline reactivation as an emergent consequence of task optimization
in noisy neural circuits.","['Nanda H. Krishna', 'Colin Bredenberg', 'Daniel Levenstein', 'Blake A. Richards', 'Guillaume Lajoie']",2025-05-22,http://arxiv.org/abs/2505.17003v1
PAEFF: Precise Alignment and Enhanced Gated Feature Fusion for Face-Voice Association,"We study the task of learning association between faces and voices, which is
gaining interest in the multimodal community lately. These methods suffer from
the deliberate crafting of negative mining procedures as well as the reliance
on the distant margin parameter. These issues are addressed by learning a joint
embedding space in which orthogonality constraints are applied to the fused
embeddings of faces and voices. However, embedding spaces of faces and voices
possess different characteristics and require spaces to be aligned before
fusing them. To this end, we propose a method that accurately aligns the
embedding spaces and fuses them with an enhanced gated fusion thereby improving
the performance of face-voice association. Extensive experiments on the
VoxCeleb dataset reveals the merits of the proposed approach.","['Abdul Hannan', 'Muhammad Arslan Manzoor', 'Shah Nawaz', 'Muhammad Irzam Liaqat', 'Markus Schedl', 'Mubashir Noman']",2025-05-22,http://arxiv.org/abs/2505.17002v1
Critical Points of Random Neural Networks,"This work investigates the expected number of critical points of random
neural networks with different activation functions as the depth increases in
the infinite-width limit. Under suitable regularity conditions, we derive
precise asymptotic formulas for the expected number of critical points of fixed
index and those exceeding a given threshold. Our analysis reveals three
distinct regimes depending on the value of the first derivative of the
covariance evaluated at 1: the expected number of critical points may converge,
grow polynomially, or grow exponentially with depth. The theoretical
predictions are supported by numerical experiments. Moreover, we provide
numerical evidence suggesting that, when the regularity condition is not
satisfied (e.g. for neural networks with ReLU as activation function), the
number of critical points increases as the map resolution increases, indicating
a potential divergence in the number of critical points.",['Simmaco Di Lillo'],2025-05-22,http://arxiv.org/abs/2505.17000v1
Do Large Language Models Excel in Complex Logical Reasoning with Formal Language?,"Large Language Models (LLMs) have been shown to achieve breakthrough
performance on complex logical reasoning tasks. Nevertheless, most existing
research focuses on employing formal language to guide LLMs to derive reliable
reasoning paths, while systematic evaluations of these capabilities are still
limited. In this paper, we aim to conduct a comprehensive evaluation of LLMs
across various logical reasoning problems utilizing formal languages. From the
perspective of three dimensions, i.e., spectrum of LLMs, taxonomy of tasks, and
format of trajectories, our key findings are: 1) Thinking models significantly
outperform Instruct models, especially when formal language is employed; 2) All
LLMs exhibit limitations in inductive reasoning capability, irrespective of
whether they use a formal language; 3) Data with PoT format achieves the best
generalization performance across other languages. Additionally, we also curate
the formal-relative training data to further enhance the small language models,
and the experimental results indicate that a simple rejected fine-tuning method
can better enable LLMs to generalize across formal languages and achieve the
best overall performance. Our codes and reports are available at
https://github.com/jiangjin1999/FormalEval.","['Jin Jiang', 'Jianing Wang', 'Yuchen Yan', 'Yang Liu', 'Jianhua Zhu', 'Mengdi Zhang', 'Xunliang Cai', 'Liangcai Gao']",2025-05-22,http://arxiv.org/abs/2505.16998v1
X-MAS: Towards Building Multi-Agent Systems with Heterogeneous LLMs,"LLM-based multi-agent systems (MAS) extend the capabilities of single LLMs by
enabling cooperation among multiple specialized agents. However, most existing
MAS frameworks rely on a single LLM to drive all agents, constraining the
system's intelligence to the limit of that model. This paper explores the
paradigm of heterogeneous LLM-driven MAS (X-MAS), where agents are powered by
diverse LLMs, elevating the system's potential to the collective intelligence
of diverse LLMs. We introduce X-MAS-Bench, a comprehensive testbed designed to
evaluate the performance of various LLMs across different domains and
MAS-related functions. As an extensive empirical study, we assess 27 LLMs
across 5 domains (encompassing 21 test sets) and 5 functions, conducting over
1.7 million evaluations to identify optimal model selections for each
domain-function combination. Building on these findings, we demonstrate that
transitioning from homogeneous to heterogeneous LLM-driven MAS can
significantly enhance system performance without requiring structural redesign.
Specifically, in a chatbot-only MAS scenario, the heterogeneous configuration
yields up to 8.4\% performance improvement on the MATH dataset. In a mixed
chatbot-reasoner scenario, the heterogeneous MAS could achieve a remarkable
47\% performance boost on the AIME dataset. Our results underscore the
transformative potential of heterogeneous LLMs in MAS, highlighting a promising
avenue for advancing scalable, collaborative AI systems.","['Rui Ye', 'Xiangrui Liu', 'Qimin Wu', 'Xianghe Pang', 'Zhenfei Yin', 'Lei Bai', 'Siheng Chen']",2025-05-22,http://arxiv.org/abs/2505.16997v1
A Unified Framework for Simultaneous Parameter and Function Discovery in Differential Equations,"Inverse problems involving differential equations often require identifying
unknown parameters or functions from data. Existing approaches, such as
Physics-Informed Neural Networks (PINNs), Universal Differential Equations
(UDEs) and Universal Physics-Informed Neural Networks (UPINNs), are effective
at isolating either parameters or functions but can face challenges when
applied simultaneously due to solution non-uniqueness. In this work, we
introduce a framework that addresses these limitations by establishing
conditions under which unique solutions can be guaranteed. To illustrate, we
apply it to examples from biological systems and ecological dynamics,
demonstrating accurate and interpretable results. Our approach significantly
enhances the potential of machine learning techniques in modeling complex
systems in science and engineering.","['Shalev Manor', 'Mohammad Kohandel']",2025-05-22,http://arxiv.org/abs/2505.16996v1
$\text{R}^2\text{ec}$: Towards Large Recommender Models with Reasoning,"Large recommender models have extended LLMs as powerful recommenders via
encoding or item generation, and recent breakthroughs in LLM reasoning
synchronously motivate the exploration of reasoning in recommendation. Current
studies usually position LLMs as external reasoning modules to yield auxiliary
thought for augmenting conventional recommendation pipelines. However, such
decoupled designs are limited in significant resource cost and suboptimal joint
optimization. To address these issues, we propose \name, a unified large
recommender model with intrinsic reasoning capabilities. Initially, we
reconceptualize the model architecture to facilitate interleaved reasoning and
recommendation in the autoregressive process. Subsequently, we propose RecPO, a
corresponding reinforcement learning framework that optimizes \name\ both the
reasoning and recommendation capabilities simultaneously in a single policy
update; RecPO introduces a fused reward scheme that solely leverages
recommendation labels to simulate the reasoning capability, eliminating
dependency on specialized reasoning annotations. Experiments on three datasets
with various baselines verify the effectiveness of \name, showing relative
improvements of 68.67\% in Hit@5 and 45.21\% in NDCG@20. Code available at
https://github.com/YRYangang/RRec.","['Runyang You', 'Yongqi Li', 'Xinyu Lin', 'Xin Zhang', 'Wenjie Wang', 'Wenjie Li', 'Liqiang Nie']",2025-05-22,http://arxiv.org/abs/2505.16994v1
Native Segmentation Vision Transformers,"Uniform downsampling remains the de facto standard for reducing spatial
resolution in vision backbones. In this work, we propose an alternative design
built around a content-aware spatial grouping layer, that dynamically assigns
tokens to a reduced set based on image boundaries and their semantic content.
Stacking our grouping layer across consecutive backbone stages results in
hierarchical segmentation that arises natively in the feature extraction
process, resulting in our coined Native Segmentation Vision Transformer. We
show that a careful design of our architecture enables the emergence of strong
segmentation masks solely from grouping layers, that is, without additional
segmentation-specific heads. This sets the foundation for a new paradigm of
native, backbone-level segmentation, which enables strong zero-shot results
without mask supervision, as well as a minimal and efficient standalone model
design for downstream segmentation tasks. Our project page is
https://research.nvidia.com/labs/dvl/projects/native-segmentation.","['Guillem Brasó', 'Aljoša Ošep', 'Laura Leal-Taixé']",2025-05-22,http://arxiv.org/abs/2505.16993v1
"PICT -- A Differentiable, GPU-Accelerated Multi-Block PISO Solver for Simulation-Coupled Learning Tasks in Fluid Dynamics","Despite decades of advancements, the simulation of fluids remains one of the
most challenging areas of in scientific computing. Supported by the necessity
of gradient information in deep learning, differentiable simulators have
emerged as an effective tool for optimization and learning in physics
simulations. In this work, we present our fluid simulator PICT, a
differentiable pressure-implicit solver coded in PyTorch with
Graphics-processing-unit (GPU) support. We first verify the accuracy of both
the forward simulation and our derived gradients in various established
benchmarks like lid-driven cavities and turbulent channel flows before we show
that the gradients provided by our solver can be used to learn complicated
turbulence models in 2D and 3D. We apply both supervised and unsupervised
training regimes using physical priors to match flow statistics. In particular,
we learn a stable sub-grid scale (SGS) model for a 3D turbulent channel flow
purely based on reference statistics. The low-resolution corrector trained with
our solver runs substantially faster than the highly resolved references, while
keeping or even surpassing their accuracy. Finally, we give additional insights
into the physical interpretation of different solver gradients, and motivate a
physically informed regularization technique. To ensure that the full potential
of PICT can be leveraged, it is published as open source:
https://github.com/tum-pbs/PICT.","['Aleksandra Franz', 'Hao Wei', 'Luca Guastoni', 'Nils Thuerey']",2025-05-22,http://arxiv.org/abs/2505.16992v1
MASLab: A Unified and Comprehensive Codebase for LLM-based Multi-Agent Systems,"LLM-based multi-agent systems (MAS) have demonstrated significant potential
in enhancing single LLMs to address complex and diverse tasks in practical
applications. Despite considerable advancements, the field lacks a unified
codebase that consolidates existing methods, resulting in redundant
re-implementation efforts, unfair comparisons, and high entry barriers for
researchers. To address these challenges, we introduce MASLab, a unified,
comprehensive, and research-friendly codebase for LLM-based MAS. (1) MASLab
integrates over 20 established methods across multiple domains, each rigorously
validated by comparing step-by-step outputs with its official implementation.
(2) MASLab provides a unified environment with various benchmarks for fair
comparisons among methods, ensuring consistent inputs and standardized
evaluation protocols. (3) MASLab implements methods within a shared streamlined
structure, lowering the barriers for understanding and extension. Building on
MASLab, we conduct extensive experiments covering 10+ benchmarks and 8 models,
offering researchers a clear and comprehensive view of the current landscape of
MAS methods. MASLab will continue to evolve, tracking the latest developments
in the field, and invite contributions from the broader open-source community.","['Rui Ye', 'Keduan Huang', 'Qimin Wu', 'Yuzhu Cai', 'Tian Jin', 'Xianghe Pang', 'Xiangrui Liu', 'Jiaqi Su', 'Chen Qian', 'Bohan Tang', 'Kaiqu Liang', 'Jiaao Chen', 'Yue Hu', 'Zhenfei Yin', 'Rongye Shi', 'Bo An', 'Yang Gao', 'Wenjun Wu', 'Lei Bai', 'Siheng Chen']",2025-05-22,http://arxiv.org/abs/2505.16988v1
T1: A Tool-Oriented Conversational Dataset for Multi-Turn Agentic Planning,"Large Language Models (LLMs) have demonstrated impressive capabilities as
intelligent agents capable of solving complex problems. However, effective
planning in scenarios involving dependencies between API or tool
calls-particularly in multi-turn conversations-remains a significant challenge.
To address this, we introduce T1, a tool-augmented, multi-domain, multi-turn
conversational dataset specifically designed to capture and manage inter-tool
dependencies across diverse domains. T1 enables rigorous evaluation of agents'
ability to coordinate tool use across nine distinct domains (4 single domain
and 5 multi-domain) with the help of an integrated caching mechanism for both
short- and long-term memory, while supporting dynamic replanning-such as
deciding whether to recompute or reuse cached results. Beyond facilitating
research on tool use and planning, T1 also serves as a benchmark for evaluating
the performance of open-source language models. We present results powered by
T1-Agent, highlighting their ability to plan and reason in complex,
tool-dependent scenarios.","['Amartya Chakraborty', 'Paresh Dashore', 'Nadia Bathaee', 'Anmol Jain', 'Anirban Das', 'Shi-Xiong Zhang', 'Sambit Sahu', 'Milind Naphade', 'Genta Indra Winata']",2025-05-22,http://arxiv.org/abs/2505.16986v1
Extremely Simple Multimodal Outlier Synthesis for Out-of-Distribution Detection and Segmentation,"Out-of-distribution (OOD) detection and segmentation are crucial for
deploying machine learning models in safety-critical applications such as
autonomous driving and robot-assisted surgery. While prior research has
primarily focused on unimodal image data, real-world applications are
inherently multimodal, requiring the integration of multiple modalities for
improved OOD detection. A key challenge is the lack of supervision signals from
unknown data, leading to overconfident predictions on OOD samples. To address
this challenge, we propose Feature Mixing, an extremely simple and fast method
for multimodal outlier synthesis with theoretical support, which can be further
optimized to help the model better distinguish between in-distribution (ID) and
OOD data. Feature Mixing is modality-agnostic and applicable to various
modality combinations. Additionally, we introduce CARLA-OOD, a novel multimodal
dataset for OOD segmentation, featuring synthetic OOD objects across diverse
scenes and weather conditions. Extensive experiments on SemanticKITTI,
nuScenes, CARLA-OOD datasets, and the MultiOOD benchmark demonstrate that
Feature Mixing achieves state-of-the-art performance with a $10 \times$ to $370
\times$ speedup. Our source code and dataset will be available at
https://github.com/mona4399/FeatureMixing.","['Moru Liu', 'Hao Dong', 'Jessica Kelly', 'Olga Fink', 'Mario Trapp']",2025-05-22,http://arxiv.org/abs/2505.16985v1
UFT: Unifying Supervised and Reinforcement Fine-Tuning,"Post-training has demonstrated its importance in enhancing the reasoning
capabilities of large language models (LLMs). The primary post-training methods
can be categorized into supervised fine-tuning (SFT) and reinforcement
fine-tuning (RFT). SFT is efficient and well-suited for small language models,
but it may lead to overfitting and limit the reasoning abilities of larger
models. In contrast, RFT generally yields better generalization but depends
heavily on the strength of the base model. To address the limitations of SFT
and RFT, we propose Unified Fine-Tuning (UFT), a novel post-training paradigm
that unifies SFT and RFT into a single, integrated process. UFT enables the
model to effectively explore solutions while incorporating informative
supervision signals, bridging the gap between memorizing and thinking
underlying existing methods. Notably, UFT outperforms both SFT and RFT in
general, regardless of model sizes. Furthermore, we theoretically prove that
UFT breaks RFT's inherent exponential sample complexity bottleneck, showing for
the first time that unified training can exponentially accelerate convergence
on long-horizon reasoning tasks.","['Mingyang Liu', 'Gabriele Farina', 'Asuman Ozdaglar']",2025-05-22,http://arxiv.org/abs/2505.16984v1
Beyond Correlation: Towards Causal Large Language Model Agents in Biomedicine,"Large Language Models (LLMs) show promise in biomedicine but lack true causal
understanding, relying instead on correlations. This paper envisions causal LLM
agents that integrate multimodal data (text, images, genomics, etc.) and
perform intervention-based reasoning to infer cause-and-effect. Addressing this
requires overcoming key challenges: designing safe, controllable agentic
frameworks; developing rigorous benchmarks for causal evaluation; integrating
heterogeneous data sources; and synergistically combining LLMs with structured
knowledge (KGs) and formal causal inference tools. Such agents could unlock
transformative opportunities, including accelerating drug discovery through
automated hypothesis generation and simulation, enabling personalized medicine
through patient-specific causal models. This research agenda aims to foster
interdisciplinary efforts, bridging causal concepts and foundation models to
develop reliable AI partners for biomedical progress.","['Adib Bazgir', 'Amir Habibdoust Lafmajani', 'Yuwen Zhang']",2025-05-22,http://arxiv.org/abs/2505.16982v1
Know the Ropes: A Heuristic Strategy for LLM-based Multi-Agent System Design,"Single-agent LLMs hit hard limits--finite context, role overload, and brittle
domain transfer. Conventional multi-agent fixes soften those edges yet expose
fresh pains: ill-posed decompositions, fuzzy contracts, and verification
overhead that blunts the gains. We therefore present Know-The-Ropes (KtR), a
framework that converts domain priors into an algorithmic blueprint hierarchy,
in which tasks are recursively split into typed, controller-mediated subtasks,
each solved zero-shot or with the lightest viable boost (e.g.,
chain-of-thought, micro-tune, self-check). Grounded in the No-Free-Lunch
theorem, KtR trades the chase for a universal prompt for disciplined
decomposition. On the Knapsack problem (3-8 items), three GPT-4o-mini agents
raise accuracy from 3% zero-shot to 95% on size-5 instances after patching a
single bottleneck agent. On the tougher Task-Assignment problem (6-15 jobs), a
six-agent o3-mini blueprint hits 100% up to size 10 and 84% on sizes 13-15,
versus 11% zero-shot. Algorithm-aware decomposition plus targeted augmentation
thus turns modest models into reliable collaborators--no ever-larger monoliths
required.","['Zhenkun Li', 'Lingyao Li', 'Shuhang Lin', 'Yongfeng Zhang']",2025-05-22,http://arxiv.org/abs/2505.16979v1
HyGenar: An LLM-Driven Hybrid Genetic Algorithm for Few-Shot Grammar Generation,"Grammar plays a critical role in natural language processing and text/code
generation by enabling the definition of syntax, the creation of parsers, and
guiding structured outputs. Although large language models (LLMs) demonstrate
impressive capabilities across domains, their ability to infer and generate
grammars has not yet been thoroughly explored. In this paper, we aim to study
and improve the ability of LLMs for few-shot grammar generation, where grammars
are inferred from sets of a small number of positive and negative examples and
generated in Backus-Naur Form. To explore this, we introduced a novel dataset
comprising 540 structured grammar generation challenges, devised 6 metrics, and
evaluated 8 various LLMs against it. Our findings reveal that existing LLMs
perform sub-optimally in grammar generation. To address this, we propose an
LLM-driven hybrid genetic algorithm, namely HyGenar, to optimize grammar
generation. HyGenar achieves substantial improvements in both the syntactic and
semantic correctness of generated grammars across LLMs.","['Weizhi Tang', 'Yixuan Li', 'Chris Sypherd', 'Elizabeth Polgreen', 'Vaishak Belle']",2025-05-22,http://arxiv.org/abs/2505.16978v1
"CASS: Nvidia to AMD Transpilation with Data, Models, and Benchmark","We introduce \texttt{CASS}, the first large-scale dataset and model suite for
cross-architecture GPU code transpilation, targeting both source-level
(CUDA~$\leftrightarrow$~HIP) and assembly-level (Nvidia
SASS~$\leftrightarrow$~AMD RDNA3) translation. The dataset comprises 70k
verified code pairs across host and device, addressing a critical gap in
low-level GPU code portability. Leveraging this resource, we train the
\texttt{CASS} family of domain-specific language models, achieving 95\% source
translation accuracy and 37.5\% assembly translation accuracy, substantially
outperforming commercial baselines such as GPT-4o, Claude, and Hipify. Our
generated code matches native performance in over 85\% of test cases,
preserving runtime and memory behavior. To support rigorous evaluation, we
introduce \texttt{CASS-Bench}, a curated benchmark spanning 16 GPU domains with
ground-truth execution. All data, models, and evaluation tools are released as
open source to foster progress in GPU compiler tooling, binary compatibility,
and LLM-guided hardware translation. Dataset and benchmark are on
\href{https://huggingface.co/datasets/MBZUAI/cass}{\textcolor{blue}{HuggingFace}},
with code at
\href{https://github.com/GustavoStahl/CASS}{\textcolor{blue}{GitHub}}.","['Ahmed Heakl', 'Sarim Hashmi', 'Gustavo Bertolo Stahl', 'Seung Hun Eddie Han', 'Salman Khan', 'Abdulrahman Mahmoud']",2025-05-22,http://arxiv.org/abs/2505.16968v1
Fixing Data That Hurts Performance: Cascading LLMs to Relabel Hard Negatives for Robust Information Retrieval,"Training robust retrieval and reranker models typically relies on large-scale
retrieval datasets; for example, the BGE collection contains 1.6 million
query-passage pairs sourced from various data sources. However, we find that
certain datasets can negatively impact model effectiveness -- pruning 8 out of
15 datasets from the BGE collection reduces the training set size by
2.35$\times$ and increases nDCG@10 on BEIR by 1.0 point. This motivates a
deeper examination of training data quality, with a particular focus on ""false
negatives"", where relevant passages are incorrectly labeled as irrelevant. We
propose a simple, cost-effective approach using cascading LLM prompts to
identify and relabel hard negatives. Experimental results show that relabeling
false negatives with true positives improves both E5 (base) and Qwen2.5-7B
retrieval models by 0.7-1.4 nDCG@10 on BEIR and by 1.7-1.8 nDCG@10 on zero-shot
AIR-Bench evaluation. Similar gains are observed for rerankers fine-tuned on
the relabeled data, such as Qwen2.5-3B on BEIR. The reliability of the
cascading design is further supported by human annotation results, where we
find judgment by GPT-4o shows much higher agreement with humans than
GPT-4o-mini.","['Nandan Thakur', 'Crystina Zhang', 'Xueguang Ma', 'Jimmy Lin']",2025-05-22,http://arxiv.org/abs/2505.16967v1
BP-Seg: A graphical model approach to unsupervised and non-contiguous text segmentation using belief propagation,"Text segmentation based on the semantic meaning of sentences is a fundamental
task with broad utility in many downstream applications. In this paper, we
propose a graphical model-based unsupervised learning approach, named BP-Seg
for efficient text segmentation. Our method not only considers local coherence,
capturing the intuition that adjacent sentences are often more related, but
also effectively groups sentences that are distant in the text yet semantically
similar. This is achieved through belief propagation on the carefully
constructed graphical models. Experimental results on both an illustrative
example and a dataset with long-form documents demonstrate that our method
performs favorably compared to competing approaches.","['Fengyi Li', 'Kayhan Behdin', 'Natesh Pillai', 'Xiaofeng Wang', 'Zhipeng Wang', 'Ercan Yildiz']",2025-05-22,http://arxiv.org/abs/2505.16965v1
Bigger Isn't Always Memorizing: Early Stopping Overparameterized Diffusion Models,"Diffusion probabilistic models have become a cornerstone of modern generative
AI, yet the mechanisms underlying their generalization remain poorly
understood. In fact, if these models were perfectly minimizing their training
loss, they would just generate data belonging to their training set, i.e.,
memorize, as empirically found in the overparameterized regime. We revisit this
view by showing that, in highly overparameterized diffusion models,
generalization in natural data domains is progressively achieved during
training before the onset of memorization. Our results, ranging from image to
language diffusion models, systematically support the empirical law that
memorization time is proportional to the dataset size. Generalization vs.
memorization is then best understood as a competition between time scales. We
show that this phenomenology is recovered in diffusion models learning a simple
probabilistic context-free grammar with random rules, where generalization
corresponds to the hierarchical acquisition of deeper grammar rules as training
time grows, and the generalization cost of early stopping can be characterized.
We summarize these results in a phase diagram. Overall, our results support
that a principled early-stopping criterion - scaling with dataset size - can
effectively optimize generalization while avoiding memorization, with direct
implications for hyperparameter transfer and privacy-sensitive applications.","['Alessandro Favero', 'Antonio Sclocchi', 'Matthieu Wyart']",2025-05-22,http://arxiv.org/abs/2505.16959v1
"Invisible Prompts, Visible Threats: Malicious Font Injection in External Resources for Large Language Models","Large Language Models (LLMs) are increasingly equipped with capabilities of
real-time web search and integrated with protocols like Model Context Protocol
(MCP). This extension could introduce new security vulnerabilities. We present
a systematic investigation of LLM vulnerabilities to hidden adversarial prompts
through malicious font injection in external resources like webpages, where
attackers manipulate code-to-glyph mapping to inject deceptive content which
are invisible to users. We evaluate two critical attack scenarios: (1)
""malicious content relay"" and (2) ""sensitive data leakage"" through MCP-enabled
tools. Our experiments reveal that indirect prompts with injected malicious
font can bypass LLM safety mechanisms through external resources, achieving
varying success rates based on data sensitivity and prompt design. Our research
underscores the urgent need for enhanced security measures in LLM deployments
when processing external content.","['Junjie Xiong', 'Changjia Zhu', 'Shuhang Lin', 'Chong Zhang', 'Yongfeng Zhang', 'Yao Liu', 'Lingyao Li']",2025-05-22,http://arxiv.org/abs/2505.16957v1
A Comprehensive Evaluation of Contemporary ML-Based Solvers for Combinatorial Optimization,"Machine learning (ML) has demonstrated considerable potential in supporting
model design and optimization for combinatorial optimization (CO) problems.
However, much of the progress to date has been evaluated on small-scale,
synthetic datasets, raising concerns about the practical effectiveness of
ML-based solvers in real-world, large-scale CO scenarios. Additionally, many
existing CO benchmarks lack sufficient training data, limiting their utility
for evaluating data-driven approaches. To address these limitations, we
introduce FrontierCO, a comprehensive benchmark that covers eight canonical CO
problem types and evaluates 16 representative ML-based solvers--including graph
neural networks and large language model (LLM) agents. FrontierCO features
challenging instances drawn from industrial applications and frontier CO
research, offering both realistic problem difficulty and abundant training
data. Our empirical results provide critical insights into the strengths and
limitations of current ML methods, helping to guide more robust and practically
relevant advances at the intersection of machine learning and combinatorial
optimization. Our data is available at
https://huggingface.co/datasets/CO-Bench/FrontierCO.","['Shengyu Feng', 'Weiwei Sun', 'Shanda Li', 'Ameet Talwalkar', 'Yiming Yang']",2025-05-22,http://arxiv.org/abs/2505.16952v1
ICYM2I: The illusion of multimodal informativeness under missingness,"Multimodal learning is of continued interest in artificial intelligence-based
applications, motivated by the potential information gain from combining
different types of data. However, modalities collected and curated during
development may differ from the modalities available at deployment due to
multiple factors including cost, hardware failure, or -- as we argue in this
work -- the perceived informativeness of a given modality. Na{\""i}ve estimation
of the information gain associated with including an additional modality
without accounting for missingness may result in improper estimates of that
modality's value in downstream tasks. Our work formalizes the problem of
missingness in multimodal learning and demonstrates the biases resulting from
ignoring this process. To address this issue, we introduce ICYM2I (In Case You
Multimodal Missed It), a framework for the evaluation of predictive performance
and information gain under missingness through inverse probability
weighting-based correction. We demonstrate the importance of the proposed
adjustment to estimate information gain under missingness on synthetic,
semi-synthetic, and real-world medical datasets.","['Young Sang Choi', 'Vincent Jeanselme', 'Pierre Elias', 'Shalmali Joshi']",2025-05-22,http://arxiv.org/abs/2505.16953v1
Bottlenecked Transformers: Periodic KV Cache Abstraction for Generalised Reasoning,"Despite their impressive capabilities, Large Language Models struggle with
generalisation beyond their training distribution, often exhibiting
sophisticated pattern interpolation rather than true abstract reasoning
(extrapolation). In this work, we approach this limitation through the lens of
Information Bottleneck (IB) theory, which posits that model generalisation
emerges from an optimal balance between input compression and retention of
predictive information in latent representations. We prove using IB theory that
decoder-only Transformers are inherently constrained in their ability to form
task-optimal sequence representations. We then use this result to demonstrate
that periodic global transformation of the internal sequence-level
representations (KV cache) is a necessary computational step for improving
Transformer generalisation in reasoning tasks. Based on these theoretical
insights, we propose a modification to the Transformer architecture, in the
form of an additional module that globally rewrites the KV cache at periodic
intervals, shifting its capacity away from memorising input prefixes and toward
encoding features most useful for predicting future tokens. Our model delivers
substantial gains on mathematical reasoning benchmarks, outperforming both
vanilla Transformers with up to 3.5x more parameters, as well as
heuristic-driven pruning mechanisms for cache compression. Our approach can be
seen as a principled generalisation of existing KV-cache compression methods;
whereas such methods focus solely on compressing input representations, they
often do so at the expense of retaining predictive information, and thus their
capabilities are inherently bounded by those of an unconstrained model. This
establishes a principled framework to manipulate Transformer memory using
information theory, addressing fundamental reasoning limitations that scaling
alone cannot overcome.","['Adnan Oomerjee', 'Zafeirios Fountas', 'Zhongwei Yu', 'Haitham Bou-Ammar', 'Jun Wang']",2025-05-22,http://arxiv.org/abs/2505.16950v1
MixAT: Combining Continuous and Discrete Adversarial Training for LLMs,"Despite recent efforts in Large Language Models (LLMs) safety and alignment,
current adversarial attacks on frontier LLMs are still able to force harmful
generations consistently. Although adversarial training has been widely studied
and shown to significantly improve the robustness of traditional machine
learning models, its strengths and weaknesses in the context of LLMs are less
understood. Specifically, while existing discrete adversarial attacks are
effective at producing harmful content, training LLMs with concrete adversarial
prompts is often computationally expensive, leading to reliance on continuous
relaxations. As these relaxations do not correspond to discrete input tokens,
such latent training methods often leave models vulnerable to a diverse set of
discrete attacks. In this work, we aim to bridge this gap by introducing MixAT,
a novel method that combines stronger discrete and faster continuous attacks
during training. We rigorously evaluate MixAT across a wide spectrum of
state-of-the-art attacks, proposing the At Least One Attack Success Rate
(ALO-ASR) metric to capture the worst-case vulnerability of models. We show
MixAT achieves substantially better robustness (ALO-ASR < 20%) compared to
prior defenses (ALO-ASR > 50%), while maintaining a runtime comparable to
methods based on continuous relaxations. We further analyze MixAT in realistic
deployment settings, exploring how chat templates, quantization, low-rank
adapters, and temperature affect both adversarial training and evaluation,
revealing additional blind spots in current methodologies. Our results
demonstrate that MixAT's discrete-continuous defense offers a principled and
superior robustness-accuracy tradeoff with minimal computational overhead,
highlighting its promise for building safer LLMs. We provide our code and
models at https://github.com/insait-institute/MixAT.","['Csaba Dékány', 'Stefan Balauca', 'Robin Staab', 'Dimitar I. Dimitrov', 'Martin Vechev']",2025-05-22,http://arxiv.org/abs/2505.16947v1
NY Real Estate Racial Equity Analysis via Applied Machine Learning,"This study analyzes tract-level real estate ownership patterns in New York
State (NYS) and New York City (NYC) to uncover racial disparities. We use an
advanced race/ethnicity imputation model (LSTM+Geo with XGBoost filtering,
validated at 89.2% accuracy) to compare the predicted racial composition of
property owners to the resident population from census data. We examine both a
Full Model (statewide) and a Name-Only LSTM Model (NYC) to assess how
incorporating geospatial context affects our predictions and disparity
estimates. The results reveal significant inequities: White individuals hold a
disproportionate share of properties and property value relative to their
population, while Black, Hispanic, and Asian communities are underrepresented
as property owners. These disparities are most pronounced in minority-majority
neighborhoods, where ownership is predominantly White despite a predominantly
non-White population. Corporate ownership (LLCs, trusts, etc.) exacerbates
these gaps by reducing owner-occupied opportunities in urban minority
communities. We provide a breakdown of ownership vs. population by race for
majority-White, -Black, -Hispanic, and -Asian tracts, identify those with
extreme ownership disparities, and compare patterns in urban, suburban, and
rural contexts. The findings underscore persistent racial inequity in property
ownership, reflecting broader historical and socio-economic forces, and
highlight the importance of data-driven approaches to address these issues.","['Sanjana Chalavadi', 'Andrei Pastor', 'Terry Leitch']",2025-05-22,http://arxiv.org/abs/2505.16946v1
AGENTIF: Benchmarking Instruction Following of Large Language Models in Agentic Scenarios,"Large Language Models (LLMs) have demonstrated advanced capabilities in
real-world agentic applications. Growing research efforts aim to develop
LLM-based agents to address practical demands, introducing a new challenge:
agentic scenarios often involve lengthy instructions with complex constraints,
such as extended system prompts and detailed tool specifications. While
adherence to such instructions is crucial for agentic applications, whether
LLMs can reliably follow them remains underexplored. In this paper, we
introduce AgentIF, the first benchmark for systematically evaluating LLM
instruction following ability in agentic scenarios. AgentIF features three key
characteristics: (1) Realistic, constructed from 50 real-world agentic
applications. (2) Long, averaging 1,723 words with a maximum of 15,630 words.
(3) Complex, averaging 11.9 constraints per instruction, covering diverse
constraint types, such as tool specifications and condition constraints. To
construct AgentIF, we collect 707 human-annotated instructions across 50
agentic tasks from industrial application agents and open-source agentic
systems. For each instruction, we annotate the associated constraints and
corresponding evaluation metrics, including code-based evaluation, LLM-based
evaluation, and hybrid code-LLM evaluation. We use AgentIF to systematically
evaluate existing advanced LLMs. We observe that current models generally
perform poorly, especially in handling complex constraint structures and tool
specifications. We further conduct error analysis and analytical experiments on
instruction length and meta constraints, providing some findings about the
failure modes of existing LLMs. We have released the code and data to
facilitate future research.","['Yunjia Qi', 'Hao Peng', 'Xiaozhi Wang', 'Amy Xin', 'Youfeng Liu', 'Bin Xu', 'Lei Hou', 'Juanzi Li']",2025-05-22,http://arxiv.org/abs/2505.16944v1
Efficient Correlation Volume Sampling for Ultra-High-Resolution Optical Flow Estimation,"Recent optical flow estimation methods often employ local cost sampling from
a dense all-pairs correlation volume. This results in quadratic computational
and memory complexity in the number of pixels. Although an alternative
memory-efficient implementation with on-demand cost computation exists, this is
slower in practice and therefore prior methods typically process images at
reduced resolutions, missing fine-grained details.
  To address this, we propose a more efficient implementation of the all-pairs
correlation volume sampling, still matching the exact mathematical operator as
defined by RAFT. Our approach outperforms on-demand sampling by up to 90% while
maintaining low memory usage, and performs on par with the default
implementation with up to 95% lower memory usage. As cost sampling makes up a
significant portion of the overall runtime, this can translate to up to 50%
savings for the total end-to-end model inference in memory-constrained
environments. Our evaluation of existing methods includes an 8K
ultra-high-resolution dataset and an additional inference-time modification of
the recent SEA-RAFT method. With this, we achieve state-of-the-art results at
high resolutions both in accuracy and efficiency.","['Karlis Martins Briedis', 'Markus Gross', 'Christopher Schroers']",2025-05-22,http://arxiv.org/abs/2505.16942v1
FoMoH: A clinically meaningful foundation model evaluation for structured electronic health records,"Foundation models hold significant promise in healthcare, given their
capacity to extract meaningful representations independent of downstream tasks.
This property has enabled state-of-the-art performance across several clinical
applications trained on structured electronic health record (EHR) data, even in
settings with limited labeled data, a prevalent challenge in healthcare.
However, there is little consensus on these models' potential for clinical
utility due to the lack of desiderata of comprehensive and meaningful tasks and
sufficiently diverse evaluations to characterize the benefit over conventional
supervised learning. To address this gap, we propose a suite of clinically
meaningful tasks spanning patient outcomes, early prediction of acute and
chronic conditions, including desiderata for robust evaluations. We evaluate
state-of-the-art foundation models on EHR data consisting of 5 million patients
from Columbia University Irving Medical Center (CUMC), a large urban academic
medical center in New York City, across 14 clinically relevant tasks. We
measure overall accuracy, calibration, and subpopulation performance to surface
tradeoffs based on the choice of pre-training, tokenization, and data
representation strategies. Our study aims to advance the empirical evaluation
of structured EHR foundation models and guide the development of future
healthcare foundation models.","['Chao Pang', 'Vincent Jeanselme', 'Young Sang Choi', 'Xinzhuo Jiang', 'Zilin Jing', 'Aparajita Kashyap', 'Yuta Kobayashi', 'Yanwei Li', 'Florent Pollet', 'Karthik Natarajan', 'Shalmali Joshi']",2025-05-22,http://arxiv.org/abs/2505.16941v1
NovelSeek: When Agent Becomes the Scientist -- Building Closed-Loop System from Hypothesis to Verification,"Artificial Intelligence (AI) is accelerating the transformation of scientific
research paradigms, not only enhancing research efficiency but also driving
innovation. We introduce NovelSeek, a unified closed-loop multi-agent framework
to conduct Autonomous Scientific Research (ASR) across various scientific
research fields, enabling researchers to tackle complicated problems in these
fields with unprecedented speed and precision. NovelSeek highlights three key
advantages: 1) Scalability: NovelSeek has demonstrated its versatility across
12 scientific research tasks, capable of generating innovative ideas to enhance
the performance of baseline code. 2) Interactivity: NovelSeek provides an
interface for human expert feedback and multi-agent interaction in automated
end-to-end processes, allowing for the seamless integration of domain expert
knowledge. 3) Efficiency: NovelSeek has achieved promising performance gains in
several scientific fields with significantly less time cost compared to human
efforts. For instance, in reaction yield prediction, it increased from 27.6% to
35.4% in just 12 hours; in enhancer activity prediction, accuracy rose from
0.52 to 0.79 with only 4 hours of processing; and in 2D semantic segmentation,
precision advanced from 78.8% to 81.0% in a mere 30 hours.","['NovelSeek Team', 'Bo Zhang', 'Shiyang Feng', 'Xiangchao Yan', 'Jiakang Yuan', 'Zhiyin Yu', 'Xiaohan He', 'Songtao Huang', 'Shaowei Hou', 'Zheng Nie', 'Zhilong Wang', 'Jinyao Liu', 'Runmin Ma', 'Tianshuo Peng', 'Peng Ye', 'Dongzhan Zhou', 'Shufei Zhang', 'Xiaosong Wang', 'Yilan Zhang', 'Meng Li', 'Zhongying Tu', 'Xiangyu Yue', 'Wangli Ouyang', 'Bowen Zhou', 'Lei Bai']",2025-05-22,http://arxiv.org/abs/2505.16938v1
SPAR: Self-supervised Placement-Aware Representation Learning for Multi-Node IoT Systems,"This work develops the underpinnings of self-supervised placement-aware
representation learning given spatially-distributed (multi-view and multimodal)
sensor observations, motivated by the need to represent external environmental
state in multi-sensor IoT systems in a manner that correctly distills spatial
phenomena from the distributed multi-vantage observations. The objective of
sensing in IoT systems is, in general, to collectively represent an externally
observed environment given multiple vantage points from which sensory
observations occur. Pretraining of models that help interpret sensor data must
therefore encode the relation between signals observed by sensors and the
observers' vantage points in order to attain a representation that encodes the
observed spatial phenomena in a manner informed by the specific placement of
the measuring instruments, while allowing arbitrary placement. The work
significantly advances self-supervised model pretraining from IoT signals
beyond current solutions that often overlook the distinctive spatial nature of
IoT data. Our framework explicitly learns the dependencies between measurements
and geometric observer layouts and structural characteristics, guided by a core
design principle: the duality between signals and observer positions. We
further provide theoretical analyses from the perspectives of information
theory and occlusion-invariant representation learning to offer insight into
the rationale behind our design. Experiments on three real-world
datasets--covering vehicle monitoring, human activity recognition, and
earthquake localization--demonstrate the superior generalizability and
robustness of our method across diverse modalities, sensor placements,
application-level inference tasks, and spatial scales.","['Yizhuo Chen', 'Tianchen Wang', 'You Lyu', 'Yanlan Hu', 'Jinyang Li', 'Tomoyoshi Kimura', 'Hongjue Zhao', 'Yigong Hu', 'Denizhan Kara', 'Tarek Abdelzaher']",2025-05-22,http://arxiv.org/abs/2505.16936v1
LLaDA-V: Large Language Diffusion Models with Visual Instruction Tuning,"In this work, we introduce LLaDA-V, a purely diffusion-based Multimodal Large
Language Model (MLLM) that integrates visual instruction tuning with masked
diffusion models, representing a departure from the autoregressive paradigms
dominant in current multimodal approaches. Built upon LLaDA, a representative
large language diffusion model, LLaDA-V incorporates a vision encoder and MLP
connector that projects visual features into the language embedding space,
enabling effective multimodal alignment. Our empirical investigation reveals
several intriguing results: First, LLaDA-V demonstrates promising multimodal
performance despite its language model being weaker on purely textual tasks
than counterparts like LLaMA3-8B and Qwen2-7B. When trained on the same
instruction data, LLaDA-V is highly competitive to LLaMA3-V across multimodal
tasks with better data scalability. It also narrows the performance gap to
Qwen2-VL, suggesting the effectiveness of its architecture for multimodal
tasks. Second, LLaDA-V achieves state-of-the-art performance in multimodal
understanding compared to existing hybrid autoregressive-diffusion and purely
diffusion-based MLLMs. Our findings suggest that large language diffusion
models show promise in multimodal contexts and warrant further investigation in
future research. Project page and codes:
https://ml-gsai.github.io/LLaDA-V-demo/.","['Zebin You', 'Shen Nie', 'Xiaolu Zhang', 'Jun Hu', 'Jun Zhou', 'Zhiwu Lu', 'Ji-Rong Wen', 'Chongxuan Li']",2025-05-22,http://arxiv.org/abs/2505.16933v1
The Polar Express: Optimal Matrix Sign Methods and Their Application to the Muon Algorithm,"Computing the polar decomposition and the related matrix sign function, has
been a well-studied problem in numerical analysis for decades. More recently,
it has emerged as an important subroutine in deep learning, particularly within
the Muon optimization framework. However, the requirements in this setting
differ significantly from those of traditional numerical analysis. In deep
learning, methods must be highly efficient and GPU-compatible, but high
accuracy is often unnecessary. As a result, classical algorithms like
Newton-Schulz (which suffers from slow initial convergence) and methods based
on rational functions (which rely on QR decompositions or matrix inverses) are
poorly suited to this context. In this work, we introduce Polar Express, a
GPU-friendly algorithm for computing the polar decomposition. Like classical
polynomial methods such as Newton-Schulz, our approach uses only matrix-matrix
multiplications, making it GPU-compatible. Motivated by earlier work of Chen &
Chow and Nakatsukasa & Freund, Polar Express adapts the polynomial update rule
at each iteration by solving a minimax optimization problem, and we prove that
it enjoys a strong worst-case optimality guarantee. This property ensures both
rapid early convergence and fast asymptotic convergence. We also address
finite-precision issues, making it stable in bfloat16 in practice. We apply
Polar Express within the Muon optimization framework and show consistent
improvements in validation loss on large-scale models such as GPT-2,
outperforming recent alternatives across a range of learning rates.","['Noah Amsel', 'David Persson', 'Christopher Musco', 'Robert Gower']",2025-05-22,http://arxiv.org/abs/2505.16932v1
"Beyond Needle(s) in the Embodied Haystack: Environment, Architecture, and Training Considerations for Long Context Reasoning","We introduce $\infty$-THOR, a new framework for long-horizon embodied tasks
that advances long-context understanding in embodied AI. $\infty$-THOR
provides: (1) a generation framework for synthesizing scalable, reproducible,
and unlimited long-horizon trajectories; (2) a novel embodied QA task,
Needle(s) in the Embodied Haystack, where multiple scattered clues across
extended trajectories test agents' long-context reasoning ability; and (3) a
long-horizon dataset and benchmark suite featuring complex tasks that span
hundreds of environment steps, each paired with ground-truth action sequences.
To enable this capability, we explore architectural adaptations, including
interleaved Goal-State-Action modeling, context extension techniques, and
Context Parallelism, to equip LLM-based agents for extreme long-context
reasoning and interaction. Experimental results and analyses highlight the
challenges posed by our benchmark and provide insights into training strategies
and model behaviors under long-horizon conditions. Our work provides a
foundation for the next generation of embodied AI systems capable of robust,
long-term reasoning and planning.","['Bosung Kim', 'Prithviraj Ammanabrolu']",2025-05-22,http://arxiv.org/abs/2505.16928v1
Latent Principle Discovery for Language Model Self-Improvement,"When language model (LM) users aim to improve the quality of its generations,
it is crucial to specify concrete behavioral attributes that the model should
strive to reflect. However, curating such principles across many domains, even
non-exhaustively, requires a labor-intensive annotation process. To automate
this process, we propose eliciting these latent attributes guiding model
reasoning towards human-preferred responses by explicitly modeling them in a
self-correction setting. Our approach mines new principles from the LM itself
and compresses the discovered elements to an interpretable set via clustering.
Specifically, we employ an approximation of posterior-regularized Monte Carlo
Expectation-Maximization to both identify a condensed set of the most effective
latent principles and teach the LM to strategically invoke them in order to
intrinsically refine its responses. We demonstrate that bootstrapping our
algorithm over multiple iterations enables smaller language models (7-8B
parameters) to self-improve, achieving +8-10% in AlpacaEval win-rate, an
average of +0.3 on MT-Bench, and +19-23% in principle-following win-rate on
IFEval. We also show that clustering the principles yields interpretable and
diverse model-generated constitutions while retaining model performance. The
gains our method achieves highlight the potential of automated,
principle-driven post-training recipes toward continual self-improvement.","['Keshav Ramji', 'Tahira Naseem', 'Ramón Fernandez Astudillo']",2025-05-22,http://arxiv.org/abs/2505.16927v1
Risk-Averse Reinforcement Learning with Itakura-Saito Loss,"Risk-averse reinforcement learning finds application in various high-stakes
fields. Unlike classical reinforcement learning, which aims to maximize
expected returns, risk-averse agents choose policies that minimize risk,
occasionally sacrificing expected value. These preferences can be framed
through utility theory. We focus on the specific case of the exponential
utility function, where we can derive the Bellman equations and employ various
reinforcement learning algorithms with few modifications. However, these
methods suffer from numerical instability due to the need for exponent
computation throughout the process. To address this, we introduce a numerically
stable and mathematically sound loss function based on the Itakura-Saito
divergence for learning state-value and action-value functions. We evaluate our
proposed loss function against established alternatives, both theoretically and
empirically. In the experimental section, we explore multiple financial
scenarios, some with known analytical solutions, and show that our loss
function outperforms the alternatives.","['Igor Udovichenko', 'Olivier Croissant', 'Anita Toleutaeva', 'Evgeny Burnaev', 'Alexander Korotin']",2025-05-22,http://arxiv.org/abs/2505.16925v1
TULiP: Test-time Uncertainty Estimation via Linearization and Weight Perturbation,"A reliable uncertainty estimation method is the foundation of many modern
out-of-distribution (OOD) detectors, which are critical for safe deployments of
deep learning models in the open world. In this work, we propose TULiP, a
theoretically-driven post-hoc uncertainty estimator for OOD detection. Our
approach considers a hypothetical perturbation applied to the network before
convergence. Based on linearized training dynamics, we bound the effect of such
perturbation, resulting in an uncertainty score computable by perturbing model
parameters. Ultimately, our approach computes uncertainty from a set of sampled
predictions. We visualize our bound on synthetic regression and classification
datasets. Furthermore, we demonstrate the effectiveness of TULiP using
large-scale OOD detection benchmarks for image classification. Our method
exhibits state-of-the-art performance, particularly for near-distribution
samples.","['Yuhui Zhang', 'Dongshen Wu', 'Yuichiro Wada', 'Takafumi Kanamori']",2025-05-22,http://arxiv.org/abs/2505.16923v1
Scalable and Interpretable Contextual Bandits: A Literature Review and Retail Offer Prototype,"This paper presents a concise review of Contextual Multi-Armed Bandit (CMAB)
methods and introduces an experimental framework for scalable, interpretable
offer selection, addressing the challenge of fast-changing offers. The approach
models context at the product category level, allowing offers to span multiple
categories and enabling knowledge transfer across similar offers. This improves
learning efficiency and generalization in dynamic environments. The framework
extends standard CMAB methodology to support multi-category contexts, and
achieves scalability through efficient feature engineering and modular design.
Advanced features such as MPG (Member Purchase Gap) and MF (Matrix
Factorization) capture nuanced user-offer interactions, with implementation in
Python for practical deployment.
  A key contribution is interpretability at scale: logistic regression models
yield transparent weight vectors, accessible via a large language model (LLM)
interface for real-time, user-level tracking and explanation of evolving
preferences. This enables the generation of detailed member profiles and
identification of behavioral patterns, supporting personalized offer
optimization and enhancing trust in automated decisions. By situating our
prototype alongside established paradigms like Generalized Linear Models and
Thompson Sampling, we demonstrate its value for both research and real-world
CMAB applications.","['Nikola Tankovic', 'Robert Sajina']",2025-05-22,http://arxiv.org/abs/2505.16918v1
DetailMaster: Can Your Text-to-Image Model Handle Long Prompts?,"While recent text-to-image (T2I) models show impressive capabilities in
synthesizing images from brief descriptions, their performance significantly
degrades when confronted with long, detail-intensive prompts required in
professional applications. We present DetailMaster, the first comprehensive
benchmark specifically designed to evaluate T2I models' systematical abilities
to handle extended textual inputs that contain complex compositional
requirements. Our benchmark introduces four critical evaluation dimensions:
Character Attributes, Structured Character Locations, Multi-Dimensional Scene
Attributes, and Explicit Spatial/Interactive Relationships. The benchmark
comprises long and detail-rich prompts averaging 284.89 tokens, with high
quality validated by expert annotators. Evaluation on 7 general-purpose and 5
long-prompt-optimized T2I models reveals critical performance limitations:
state-of-the-art models achieve merely ~50% accuracy in key dimensions like
attribute binding and spatial reasoning, while all models showing progressive
performance degradation as prompt length increases. Our analysis highlights
systemic failures in structural comprehension and detail overload handling,
motivating future research into architectures with enhanced compositional
reasoning. We open-source the dataset, data curation code, and evaluation tools
to advance detail-rich T2I generation and enable broad applications that would
otherwise be infeasible due to the lack of a dedicated benchmark.","['Qirui Jiao', 'Daoyuan Chen', 'Yilun Huang', 'Xika Lin', 'Ying Shen', 'Yaliang Li']",2025-05-22,http://arxiv.org/abs/2505.16915v1
Active Speech Enhancement: Active Speech Denoising Decliping and Deveraberation,"We introduce a new paradigm for active sound modification: Active Speech
Enhancement (ASE). While Active Noise Cancellation (ANC) algorithms focus on
suppressing external interference, ASE goes further by actively shaping the
speech signal -- both attenuating unwanted noise components and amplifying
speech-relevant frequencies -- to improve intelligibility and perceptual
quality. To enable this, we propose a novel Transformer-Mamba-based
architecture, along with a task-specific loss function designed to jointly
optimize interference suppression and signal enrichment. Our method outperforms
existing baselines across multiple speech processing tasks -- including
denoising, dereverberation, and declipping -- demonstrating the effectiveness
of active, targeted modulation in challenging acoustic environments.","['Ofir Yaish', 'Yehuda Mishaly', 'Eliya Nachmani']",2025-05-22,http://arxiv.org/abs/2505.16911v1
Unsupervised Prompting for Graph Neural Networks,"Prompt tuning methods for Graph Neural Networks (GNNs) have become popular to
address the semantic gap between pre-training and fine-tuning steps. However,
existing GNN prompting methods rely on labeled data and involve lightweight
fine-tuning for downstream tasks. Meanwhile, in-context learning methods for
Large Language Models (LLMs) have shown promising performance with no parameter
updating and no or minimal labeled data. Inspired by these approaches, in this
work, we first introduce a challenging problem setup to evaluate GNN prompting
methods. This setup encourages a prompting function to enhance a pre-trained
GNN's generalization to a target dataset under covariate shift without updating
the GNN's parameters and with no labeled data. Next, we propose a fully
unsupervised prompting method based on consistency regularization through
pseudo-labeling. We use two regularization techniques to align the prompted
graphs' distribution with the original data and reduce biased predictions.
Through extensive experiments under our problem setting, we demonstrate that
our unsupervised approach outperforms the state-of-the-art prompting methods
that have access to labels.","['Peyman Baghershahi', 'Sourav Medya']",2025-05-22,http://arxiv.org/abs/2505.16903v1
